{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image \n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from torchvision import transforms, datasets, utils\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import itertools\n",
    "import torch\n",
    "def save_variable(a,name):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(a, f)\n",
    "\n",
    "def load_variable(name):\n",
    "    with open(name, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset loading class -- specifically for cityscape\n",
    "class CityscapesDataset(Dataset):\n",
    "    def __init__(self, split, root_dir, mode='fine', transform=None, eval=False):\n",
    "        self.transform = transform\n",
    "        if mode == 'fine':\n",
    "            self.mode = 'gtFine'\n",
    "        self.split = split\n",
    "        self.yLabel_list = []\n",
    "        self.XImg_list = []\n",
    "        self.eval = eval\n",
    "\n",
    "        self.label_path = os.path.join(os.getcwd(), root_dir+'\\\\'+self.mode+'\\\\'+self.split)\n",
    "        self.rgb_path = os.path.join(os.getcwd(), root_dir+'\\\\leftImg8bit\\\\'+self.split)\n",
    "        city_list = os.listdir(self.label_path)\n",
    "        for city in city_list:\n",
    "            temp = os.listdir(self.label_path+'/'+city)\n",
    "            list_items = temp.copy()\n",
    "            for item in temp:\n",
    "                if not item.endswith('labelIds.png', 0, len(item)):\n",
    "                    list_items.remove(item)\n",
    "\n",
    "            # defining paths\n",
    "            list_items = ['/'+city+'/'+path for path in list_items]\n",
    "\n",
    "            self.yLabel_list.extend(list_items)\n",
    "            self.XImg_list.extend(\n",
    "                ['/'+city+'/'+path for path in os.listdir(self.rgb_path+'/'+city)]\n",
    "            )\n",
    "                \n",
    "    def __len__(self):\n",
    "        length = len(self.XImg_list)\n",
    "        return length      \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.rgb_path+self.XImg_list[index])\n",
    "        y = Image.open(self.label_path+self.yLabel_list[index])\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            y = self.transform(y)\n",
    "\n",
    "        image = transforms.ToTensor()(image)\n",
    "        y = np.array(y)\n",
    "        y = torch.from_numpy(y)\n",
    "        y = y.type(torch.LongTensor)\n",
    "        if self.eval:\n",
    "            return image, y, self.XImg_list[index]\n",
    "        else:\n",
    "            return image, y\n",
    "\n",
    "def get_cityscapes_data(mode,split,root_dir='datasets\\cityscapes',transforms=None,batch_size=1,eval=False,shuffle=True,pin_memory=True):\n",
    "    data = CityscapesDataset(\n",
    "        mode=mode, split=split, transform=transforms, root_dir=root_dir, eval=eval)\n",
    "\n",
    "    data_loaded = torch.utils.data.DataLoader(\n",
    "        data, batch_size=batch_size, shuffle=shuffle, pin_memory=pin_memory)\n",
    "\n",
    "    return data_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuzzyLayer(nn.Module):\n",
    "\tdef __init__(self, fuzzynum,channel, mu, sigma, static = False):\n",
    "\t\tsuper(FuzzyLayer,self).__init__()\n",
    "\t\tself.n = fuzzynum\n",
    "\t\tself.channel = channel\n",
    "\t\tself.conv1 = nn.Conv2d(self.channel,self.channel,3,padding=1)\n",
    "\t\tself.conv2 = nn.Conv2d(self.channel,self.channel,3,padding=1)\n",
    "\t\t# You can change initial mu and sigma here.\n",
    "\n",
    "\t\tif not static:\n",
    "\t\t\tself.sigma = nn.Parameter(torch.full((self.channel, self.n), 0.01).cuda())\n",
    "\t\t\tself.mu = nn.Parameter(torch.rand(self.channel,self.n).cuda())\n",
    "\t\telse:\t\n",
    "\t\t\tself.mu = mu\n",
    "\t\t\tself.sigma = sigma\n",
    "\t\tself.weight = torch.tensor(list(map(float,(range(10,10*(self.n + 1),10))))).cuda()\n",
    "\t\tself.bn1 = nn.BatchNorm2d(256, affine=True)\t\n",
    "\t\tself.bn2 = nn.BatchNorm2d(self.channel,affine=True)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.conv1(x)\n",
    "\t\ty = x.unsqueeze(2).repeat_interleave(self.n, dim=2)\n",
    "\t\ttmp = (self.weight[:,np.newaxis,np.newaxis] * torch.exp(-((y - self.mu[np.newaxis,:, :, np.newaxis, np.newaxis]) / (np.sqrt(2) * self.sigma[np.newaxis,:, : , np.newaxis, np.newaxis]))**2)).sum(dim=2)\n",
    "\t\tsum = (torch.exp(-((y - self.mu[np.newaxis,:, : , np.newaxis, np.newaxis]) / (np.sqrt(2) * self.sigma[np.newaxis,:, : , np.newaxis, np.newaxis]))**2)).sum(dim=2)\n",
    "\n",
    "\t\tfuzzy = torch.div(tmp,sum)\n",
    "\t\t\t\t\n",
    "\t\tfuzzy = self.bn2(self.conv2(self.bn1(tmp)))\n",
    "\t\treturn fuzzy\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fuzzy_UNET(nn.Module):\n",
    "    \n",
    "    def __init__(self, mu, sigma, in_channels=3, classes=1, static = False, fuzzy = False):\n",
    "        super(Fuzzy_UNET, self).__init__()\n",
    "        self.layers = [in_channels, 64, 128, 256]\n",
    "        self.double_conv_downs = nn.ModuleList(\n",
    "            [self.__double_conv(layer, layer_n) for layer, layer_n in zip(self.layers[:-1], self.layers[1:])]) \n",
    "        self.up_trans = nn.ModuleList(\n",
    "            [nn.ConvTranspose2d(layer, layer_n, kernel_size=2, stride=2)\n",
    "             for layer, layer_n in zip(self.layers[::-1][:-2], self.layers[::-1][1:-1])])\n",
    "        self.double_conv_ups = nn.ModuleList(\n",
    "        [self.__double_conv(layer, layer//2) for layer in self.layers[::-1][:-2]])\n",
    "        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.final_conv = nn.Conv2d(64, classes, kernel_size=1)\n",
    "        # You can change number of fuzzy membership function here\n",
    "        self.fuzzy = FuzzyLayer(fuzzynum=35,channel=self.layers[-1], mu = mu, sigma = sigma, static = static)\n",
    "        self.f = fuzzy\n",
    "\n",
    "        self.conv1 = nn.Conv2d(self.layers[-1],self.layers[-1],3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(self.layers[-1],self.layers[-1],3,padding=1)\n",
    "\n",
    "    \n",
    "    def __double_conv(self, in_channels, out_channels):\n",
    "        conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        return conv\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # down layers\n",
    "        concat_layers = []\n",
    "\n",
    "        for down in self.double_conv_downs:\n",
    "            x = down(x)\n",
    "            if down != self.double_conv_downs[-1]:\n",
    "                concat_layers.append(x)\n",
    "                x = self.max_pool_2x2(x)\n",
    "                \n",
    "        x = self.max_pool_2x2(x)\n",
    "        if self.f:    \n",
    "            x = self.fuzzy(x)\n",
    "            \n",
    "        concat_layers = concat_layers[::-1]\n",
    "        \n",
    "        # up layers\n",
    "        for up_trans, double_conv_up, concat_layer  in zip(self.up_trans, self.double_conv_ups, concat_layers):\n",
    "            x = up_trans(x)\n",
    "            if x.shape != concat_layer.shape:\n",
    "                x = TF.resize(x, concat_layer.shape[2:])\n",
    "            \n",
    "            concatenated = torch.cat((concat_layer, x), dim=1)\n",
    "            x = double_conv_up(concatenated)\n",
    "            \n",
    "        x = self.final_conv(x)\n",
    "        \n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda:0'\n",
    "    print('Running on the GPU')\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "    print('Running on the CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_calculation(pred, label):\n",
    "    torch.cuda.empty_cache()\n",
    "    pred_class = torch.argmax(pred, dim=1) \n",
    "    pred_class = pred_class.float()\n",
    "    acc_sum = (pred_class == label).sum()\n",
    "    acc = float(acc_sum) / torch.numel(label)\n",
    "    return acc\n",
    "\n",
    "def acc_epoch(data, model,device):\n",
    "    acc = []\n",
    "    for index, batch in enumerate(data): \n",
    "        X, y = batch\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        preds = model(X)\n",
    "        acc_ = accuracy_calculation(preds,y)\n",
    "        acc.append(acc_)\n",
    "    return np.mean(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"datasets\\\\cityscapes\"\n",
    "IMG_HEIGHT = 110  \n",
    "IMG_WIDTH = 220  \n",
    "BATCH_SIZE = 32 \n",
    "LEARNING_RATE = 0.0004\n",
    "EPOCHS = 50\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH), interpolation=Image.NEAREST),\n",
    "]) \n",
    "\n",
    "train_set = get_cityscapes_data(\n",
    "    split='train',\n",
    "    mode='fine',\n",
    "    root_dir=ROOT_DIR,\n",
    "    transforms=transform,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "test_set = get_cityscapes_data(\n",
    "    split='val',\n",
    "    mode='fine',\n",
    "    root_dir=ROOT_DIR,\n",
    "    transforms=transform,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "def train_function(data, model, optimizer, loss_fn, device):\n",
    "    print('Entering into train function')\n",
    "    loss_values = []\n",
    "    data = tqdm(data)\n",
    "    for index, batch in enumerate(data): \n",
    "        X, y = batch\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        preds = model(X)\n",
    "        loss = loss_fn(preds, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Unet_Fuzzy_Test(folder_name, name, DEVICE, static = False, fuzzy = False, mu = 0, sigma = 0):\n",
    "    \n",
    "    LOSS_VALS_Fuzzy = []\n",
    "    ACC_VALS_Fuzzy = []\n",
    "\n",
    "    unet_fuzzy = Fuzzy_UNET(mu, sigma,in_channels=3, classes=35, fuzzy = fuzzy, static = static).to(DEVICE).train()\n",
    "    optimizer = optim.Adam(unet_fuzzy.parameters(), lr=LEARNING_RATE)\n",
    "    loss_function = nn.CrossEntropyLoss(ignore_index=255).to(DEVICE)\n",
    "\n",
    "    for e in range(0, EPOCHS):\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f'Epoch: {e}')\n",
    "        loss_val = train_function(train_set, unet_fuzzy, optimizer, loss_function, DEVICE)\n",
    "        LOSS_VALS_Fuzzy.append(loss_val) \n",
    "        print(f'Loss = {loss_val}')\n",
    "        torch.cuda.empty_cache()\n",
    "        acc = acc_epoch(test_set, unet_fuzzy, DEVICE)\n",
    "        ACC_VALS_Fuzzy.append(acc)\n",
    "        print(f'Acc = {acc}')\n",
    "        if fuzzy and not static:   \n",
    "            save_variable(unet_fuzzy.fuzzy.mu,folder_name + '/unet_fuzzy_mu_' + str(e) + '.txt')\n",
    "            save_variable(unet_fuzzy.fuzzy.sigma,folder_name + '/unet_fuzzy_sigma_' + str(e) + '.txt')\n",
    "\n",
    "    save_variable(unet_fuzzy,folder_name + '/' + name + '.txt')\n",
    "    save_variable(LOSS_VALS_Fuzzy,folder_name + '/loss_' + name + '.txt')\n",
    "    save_variable(ACC_VALS_Fuzzy,folder_name + '/acc_' + name + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unet_Fuzzy_Test('Unet_Origin','unet_origin',DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unet_Fuzzy_Test('Unet_Fuzzy','unet_fuzzy',DEVICE,fuzzy=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
